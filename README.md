# Data Science & Machine Learning Portfolio

This repository acts as a **single, curated index** of my Data Science and Machine Learning work.  
Each project is implemented in a **separate GitHub repository**, while this repo provides a **structured overview of my technical depth, practical experience, and learning progression**.

The portfolio spans **data analysis, classical machine learning algorithms, unsupervised learning, model evaluation, optimization techniques, and an end-to-end capstone project**.

---

## Learning Path & Project Index

---

### Exploratory Data Analysis & Preprocessing

- **EDA and Preprocessing on Housing Dataset**  
  Performed in-depth data exploration, handled missing values, detected outliers, engineered features, and visualized key patterns to prepare the dataset for machine learning models.  
  Link: [EDA and Preprocessing on Housing Dataset](https://github.com/samhithaharini/DATA-SCIENCE.git)

---

### Regression Techniques

- **Linear Regression – Practice & Implementation**  
  Built and evaluated a regression model to predict coffee shop sales, analyzed feature impact, validated assumptions, and measured performance using appropriate regression metrics.  
  Link: [Coffee Sales Prediction](https://github.com/samhithaharini/coffee-sales-prediction.git)

- **Analyzing Student Performance Using Linear Regression (Streamlit Deployment)**  
  Developed a predictive model to estimate student academic performance and deployed it as an interactive Streamlit web application for real-time predictions.  
  Link: [Student Performance Analysis – Streamlit Deployment](https://github.com/samhithaharini/student-performance-predictor.git)

---

### Classification Algorithms

- **Logistic Regression**  
  Implemented a multi-class classification model to predict iris species based on flower measurements and evaluated performance using standard classification metrics.  
  Link: [Iris Species Prediction - Streamlit Deployment](https://github.com/samhithaharini/iris-species-prediction.git)

- **K-Nearest Neighbors (KNN)**  
  Applied distance-based classification to predict cancer diagnosis outcomes by analyzing similarities between data points in feature space.  
  Link: [Cancer Prediction System - Streamlit Deployment](https://github.com/samhithaharini/cancer-prediction-system.git)

- **Naive Bayes**  
  Built a probabilistic classifier to predict mushroom edibility using Bayesian principles and conditional probability assumptions.  
  Link: [Mushroom Prediction - Streamlit Deployment](https://github.com/samhithaharini/mushroom-prediction.git)

- **Decision Tree**  
  Designed a tree-based model for fraud detection, focusing on interpretability, decision rules, and comparison of splitting criteria.  
  Link: [Fraud Detection](https://github.com/samhithaharini/Fraud-Detection.git)

- **Random Forest**  
  Developed an ensemble-based classification model to predict survival outcomes on the Titanic dataset while analyzing feature importance.  
  Link: [Titanic Survival Prediction - Streamlit Deployment](https://github.com/samhithaharini/titanic-survival-prediction.git)

- **Support Vector Machine (SVM)**  
  Implemented an SVM classifier for breast cancer prediction, leveraging margin maximization and kernel-based decision boundaries.  
  Link: [Breast Cancer Prediction - Streamlit Deployment](https://github.com/samhithaharini/breast-cancer-prediction.git)

---

### Ensemble & Boosting Techniques

- **Ada Boosting**  
  Demonstrates how boosting improves weak learners by iteratively focusing on misclassified samples to enhance overall model accuracy.  
  

- **Gradient Boosting**  
  Explores sequential ensemble learning where models are trained to correct residual errors from previous iterations.  
  

- **XG Boosting**  
  Focuses on high-performance gradient boosting with regularization and optimized computation for large-scale datasets.  
  

---

### Unsupervised Learning

#### Clustering

- **K-Means Clustering**  
  Applied clustering techniques to segment employees into meaningful groups based on behavioral and performance-related features.  
  Link: [Employee Segmentation - Streamlit Deployment](https://github.com/samhithaharini/employee-segmentation.git)

- **Hierarchical Clustering**  
  Explores agglomerative and divisive clustering approaches using dendrograms to identify natural data groupings.  
  

- **DBSCAN**  
  Implemented density-based clustering to identify arbitrarily shaped clusters and handle noise in non-linear datasets.  
  Link: [Clustering on Make Moon](https://github.com/samhithaharini/dbscan-clustering-on-makemoons.git)

#### Dimensionality Reduction

- **Principal Component Analysis (PCA)**  
  Demonstrates feature reduction techniques to reduce dimensionality while preserving maximum variance in the data.  
  

---

### Model Evaluation & Optimization

- **Cross Validation (K-Fold)**  
  Applies K-Fold cross-validation to ensure robust and unbiased evaluation of machine learning models.  
 

- **Hyperparameter Tuning**  
  Explores systematic hyperparameter optimization using GridSearchCV and RandomizedSearchCV to improve model performance.  
  

- **Feature Selection**  
  Demonstrates filter, wrapper, and embedded feature selection techniques to enhance model efficiency and interpretability.  
 

---

### Capstone Project

- **Unique Capstone Project**  
  A comprehensive end-to-end machine learning project covering problem definition, EDA, feature engineering, model building, optimization, and deployment.  
  

---

## Tools & Technologies

- Programming Language: Python  
- Libraries: NumPy, Pandas, Matplotlib, Seaborn  
- Machine Learning: Scikit-learn, XGBoost  
- Deployment: Streamlit  

---

## Portfolio Highlights

- Strong focus on fundamentals and real-world application  
- Clear separation of concepts and implementations  
- Hands-on experience with classical ML algorithms  
- Exposure to model optimization and deployment  

---

Each linked repository contains detailed documentation, datasets, implementation code, and results.
